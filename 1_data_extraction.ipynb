{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction Using Mixtral:7x8b\n",
    "\n",
    "**This is a data extraction project in which we extract product attributes of individual product categories one by one.**\n",
    "**Problem**: \n",
    "- There is a large set of HTML text in an excel sheet that has all the product attributes of our products. <br>\n",
    "- The product attributes are not individually listed anywhere. <br>\n",
    "- We need a dataset of product attributes in which various properties of each product are listed separately, in order to build a PIM system, and to use specific attributes to SEO-optimize our webshop texts. <br>\n",
    "- The Challenge is that the text is not regular, different attributes come in a variety of formats from one product to the next. <br>\n",
    "- Another challenge is that we do not have a comprehensive list of product properties and that also needs to be created along the way. <br>\n",
    "\n",
    "**Solution**: \n",
    "1. The first solution was Text mining using Regular expressions. It was implemented on one product group by reading and analyzing product descriptions of many products and finding attributes and then generating the regex patterns to extract them. <br>\n",
    "Successful, but took a lot of time and energy. \n",
    "2. The second solution was to use SpaCy and NLP methods to extract adjective and prepositional groups such as \"mit Griff\" or \"mit Deckel\" to then use them for attribute generation. <br>\n",
    "This was a faster method than raw text mining, but the problem was a large number of false positives (adjectives that were not product attributes) and false negatives <br>\n",
    "(items that were not adjectives or prepositional groups but were attributes of the product nevertheless). \n",
    "3. This lead to trying out LLMs. The first attempt was with the transformers library. However, running into Langchain and Ollama, I found them to be faster solutions. <br>\n",
    "I used Ollama because it supported the Mixtral:7x8b model which is both compatible with structured outputs and also supports German language. <br>\n",
    "The result is the following code that functions much better in extracting all the relevant data required for our products.\n",
    "\n",
    "- Note: The prompt was an important part of the modeling which resulted in correct and coherent results that could be further processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from values import *\n",
    "import ollama\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading Productgroup Number and its name\n",
    "val = Values()\n",
    "wg_list = val.wr_gr\n",
    "wg_name = val.wr_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading the csv file that has the product information for each warengruppe (previously generated using wr_folder_building.ipynb)\n",
    "file = pd.read_csv(f'{val.parent_dir}{wg_list}/{wg_list}.csv',delimiter=';',encoding='utf-8')\n",
    "mined_text = file.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting the sets from the items to process them later\n",
    "mined_text['TEILIG'] = mined_text['BESCHREIBUNG'].str.extract(r'( *\\d+ *-*tlg.|\\d+-teilig|\\d+tlg.*|\\d+-*er *-*set|\\d+ set|\\d+ ?ply)',flags=re.IGNORECASE)\n",
    "mined_text = mined_text[mined_text['TEILIG'].isna() == True]\n",
    "mined_text = mined_text[['NUMMER','NAME','BESCHREIBUNG']]\n",
    "# mined_text = mined_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the prompt variables\n",
    "\n",
    "allowed_keys = [   \"NUMMER\", # Produkt ID\n",
    "    \"NAME\", # Produkt NAME\n",
    "    \"MATERIAL\", # Kunststoff\n",
    "    \"ART\", # Weinglas\n",
    "    \"DESIGN\", # Stillvolles Design\n",
    "    \"BREITE\", # 12 cm\n",
    "    \"TIEFE\", # 10 cm\n",
    "    \"HOEHE\", # 7 cm\n",
    "    \"ANDERE-ABMESSUNGEN\", # 8 cm\n",
    "    \"GEWICHT\", # 50 kg\n",
    "    \"HERGESTELLT\", # Deutschland\n",
    "    \"BRAND\", # Hagen Grote\n",
    "    \"QUALITAET\", # hochwertiger Edelstahl,\n",
    "    \"ANWENDUNG\", # Eisbereiter\n",
    "    \"ANDERE-EIGENSCHAFTEN\" \n",
    "\n",
    "]\n",
    "example = { \"NUMMER\" : \"111HP06\",\n",
    "    \"NAME\": \"Eisbereiter wandelt Brotbackautomaten in Eis- und Sorbetmaschine\", # Produkt NAME\n",
    "    \"MATERIAL\": \"Kunststoff\", #  Kunststoff\n",
    "    \"ART\": \"Weinglas\", # Weinglas\n",
    "    \"DESIGN\":\"Stillvolles Design\", # Stillvolles Design\n",
    "    \"BREITE\":\"12 cm\", # 12 cm\n",
    "    \"TIEFE\":\"10 cm\", # 10 cm\n",
    "    \"HOEHE\":\"7 cm\", # 7 cm\n",
    "    \"ANDERE-ABMESSUNGEN\": \"40 X 60 CM Tabletten\", # 8 cm\n",
    "    \"GEWICHT\": \"50 kg\", # 50 kg\n",
    "    \"HERGESTELLT\": \"Deutschland\", # Deutschland\n",
    "    \"BRAND\": \"Hagen Grote\",\n",
    "    \"QUALITAET\": \"hochwertiger Edelstahl\", # hochwertiger Edelstahl\n",
    "    \"ANWENDUNG\": \"Eisbereiter\", # Eisbereiter\n",
    "    \"ANDERE-EIGENSCHAFTEN\": []\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if all the keys in the list match those in the example (inconsistencies lead to poor results)\n",
    "for item in allowed_keys:\n",
    "    if item in example.keys():\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"{item} not in example.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to clean responses from the LLM\n",
    "def clean_response(response_text):\n",
    "    response_text = response_text.replace(r\"\\\\u00fc\",\"ü\")\n",
    "    try:\n",
    "        response_dict = json.loads(response_text)\n",
    "        cleaned_dict = {key: value.strip() if isinstance(value, str) else value for key, value in response_dict.items()}\n",
    "        return cleaned_dict\n",
    "\n",
    "    except json.JSONDecodeError :\n",
    "\n",
    "        print(f\"Error: The response is not a valid JSON object.\")\n",
    "        print(response_text)\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading the prompt and generating responses based on previous variables as well as extact instrctions\n",
    "cleaned_data = []\n",
    "uncleaned_data = []\n",
    "\n",
    "for id,name, beschreibung in zip(mined_text['NUMMER'],mined_text['NAME'],mined_text['BESCHREIBUNG']):\n",
    "    print(id,name)\n",
    "\n",
    "    prompt = f\"\"\"[INST]1. Bitte extrahieren Sie die Produktattribute aus dem folgenden Beschreibung und geben Sie diese als ein gültiges JSON-Objekt in deutscher Sprache aus.\n",
    "                    2. Verwenden Sie NUR die {allowed_keys} Schlüssel und ändern Sie diese nicht.\n",
    "                    3. Verwenden Sie ALLE erlaubten Schlüssel, um das JSON-Objekt zu formatieren, und wenn es keine Werte für die spezifischen Schlüssel im JSON-Objekt gibt, lassen Sie deren Werte leer.\n",
    "                    4. Beschränken Sie die Werte auf maximal 50 Zeichen. \n",
    "                    5. Füllen Sie nur die Informationen aus, die ausdrücklich im Beschreibung erwähnt werden.\n",
    "                    7. die json-Datei sollte keine ascii-Kodierung haben. Die Sprache ist deutsch und die entsprechende Kodierung sollte verwendet werden.\n",
    "                    8. Überprüfen Sie, ob die Antwort ein JSON-Objekt ist, und wenn nicht, ändern Sie sie so, dass sie ein JSON-Objekt wird.\n",
    "                    9. Überprüfen Sie doppelt, ob die Schlüssel alle genau gleich sind. \n",
    "                    10. nur und ausschließlich das JSON-Objekt ausgeben und sonst nichts. kein Text und keine Erklärung, nur das JSON-Objekt.\n",
    "                    11. deutsche Zeichen richtig kodieren und dekodieren [äëöüß] sowohl in Groß- als auch in Kleinschreibung . Verwenden Sie stattdessen KEINE Ascii-Schlüssel.\n",
    "\n",
    "\n",
    "                    Beispiel-RESPONSE: {json.dumps(example,ensure_ascii=False)}\n",
    "                    [/INST]\n",
    "                    \n",
    "                    NUMMER: {id}\n",
    "                    NAME: {name}\n",
    "                    Beschreibung: {beschreibung}\n",
    "        \"\"\"\n",
    "\n",
    "# Generate response using Mixtral 7x8b\n",
    "    response = ollama.generate(model='mixtral:latest', prompt=prompt)\n",
    "\n",
    "# Clean up the response\n",
    "    cleaned_data.append(response['response'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleaning one step further and appending responses to a new list\n",
    "new_data = []\n",
    "for id,item in enumerate(cleaned_data):\n",
    "\n",
    "    new_data.append(clean_response(item))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving clean json-objects to a json file\n",
    "with open(f'{val.parent_dir}{val.wr_gr}/{val.wr_name}_{val.wr_gr}.json', 'w', encoding=\"utf-8\") as f:\n",
    "    json.dump(new_data, f, indent=4, ensure_ascii=False)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
